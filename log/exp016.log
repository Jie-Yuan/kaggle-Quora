Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Namespace(bert_model='bert-base-multilingual-uncased', do_eval=False, do_lower_case=0, do_train=True, eval_batch_size=256, exp_name='multi_uncased_4', exp_num=16, fold=0, fp16=False, gradient_accumulation_steps=4, learning_rate=5e-05, local_rank=-1, log_dir='log/', loss_scale=128, max_seq_length=50, n_bertlayers=4, n_dev=100000, n_folds=5, n_models=3, no_cuda=False, no_weight_decay=0, num_train_epochs=3.0, optimize_on_cpu=False, output_dir='./', pos_weight=None, seed=42, seed_split=4567, stratify=1, task_name='Quora', train_batch_size=128, warmup_proportion=0.1, weight_0=1.0, weight_1=1.0)
Train shape :  (1306122, 3)

Effective batch_size: 512
02/19/2019 23:28:42 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /home/tks/.pytorch_pretrained_bert/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7
02/19/2019 23:30:00 - INFO - utility_bert -   *** Example ***
02/19/2019 23:30:00 - INFO - utility_bert -   guid: 1f07d75fede800e7d1df
02/19/2019 23:30:00 - INFO - utility_bert -   tokens: [CLS] what is lion tamin ##g ? [SEP]
02/19/2019 23:30:00 - INFO - utility_bert -   input_ids: 101 11523 10127 22311 23807 10251 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:30:00 - INFO - utility_bert -   *** Example ***
02/19/2019 23:30:00 - INFO - utility_bert -   guid: 0e5e0b66a17fb2b80c20
02/19/2019 23:30:00 - INFO - utility_bert -   tokens: [CLS] what are the most common data needs for non profits ? [SEP]
02/19/2019 23:30:00 - INFO - utility_bert -   input_ids: 101 11523 10320 10103 10889 13449 10248 25970 10139 10466 87576 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:30:00 - INFO - utility_bert -   *** Example ***
02/19/2019 23:30:00 - INFO - utility_bert -   guid: e9b7b430888864987165
02/19/2019 23:30:00 - INFO - utility_bert -   tokens: [CLS] what are some vacation package ##s that you rec ##ommen ##d ? [SEP]
02/19/2019 23:30:00 - INFO - utility_bert -   input_ids: 101 11523 10320 10970 86629 47709 10107 10203 10855 44909 55667 10163 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:30:00 - INFO - utility_bert -   *** Example ***
02/19/2019 23:30:00 - INFO - utility_bert -   guid: c236112ed981cd28356a
02/19/2019 23:30:00 - INFO - utility_bert -   tokens: [CLS] what is the nassau county sales tax rate ? [SEP]
02/19/2019 23:30:00 - INFO - utility_bert -   input_ids: 101 11523 10127 10103 25956 10663 19637 22389 17593 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:30:00 - INFO - utility_bert -   *** Example ***
02/19/2019 23:30:00 - INFO - utility_bert -   guid: d642137782d449475858
02/19/2019 23:30:00 - INFO - utility_bert -   tokens: [CLS] how does a sphere of influence re ##late to an american expansion ? [SEP]
02/19/2019 23:30:00 - INFO - utility_bert -   input_ids: 101 12548 14893 143 55903 10108 16575 11449 20849 10114 10144 10600 19650 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:30:00 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:32:44 - INFO - utility_bert -   *** Example ***
02/19/2019 23:32:44 - INFO - utility_bert -   guid: 14c71d5d5d052f551929
02/19/2019 23:32:44 - INFO - utility_bert -   tokens: [CLS] what is the reason for gibraltar [UNK] s huge population ? [SEP]
02/19/2019 23:32:44 - INFO - utility_bert -   input_ids: 101 11523 10127 10103 23065 10139 36631 100 161 37985 10509 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:32:44 - INFO - utility_bert -   *** Example ***
02/19/2019 23:32:44 - INFO - utility_bert -   guid: 31a7f774b92c3f8b06de
02/19/2019 23:32:44 - INFO - utility_bert -   tokens: [CLS] do you think re ##ject ##ion or break ##up leads to focus ##sing on career ? [SEP]
02/19/2019 23:32:44 - INFO - utility_bert -   input_ids: 101 10154 10855 21506 11449 67904 11210 10362 18979 15446 32675 10114 19753 17557 10125 13159 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:32:44 - INFO - utility_bert -   *** Example ***
02/19/2019 23:32:44 - INFO - utility_bert -   guid: 824843436610ab46ed4e
02/19/2019 23:32:44 - INFO - utility_bert -   tokens: [CLS] how does the gender gap apply to retirement ? [SEP]
02/19/2019 23:32:44 - INFO - utility_bert -   input_ids: 101 12548 14893 10103 26974 19775 46328 10114 30811 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:32:44 - INFO - utility_bert -   *** Example ***
02/19/2019 23:32:44 - INFO - utility_bert -   guid: 66329bb6e3d64d9824e6
02/19/2019 23:32:44 - INFO - utility_bert -   tokens: [CLS] what does this sentence mean " i ind ##ul ##ge you in the right to be wrong " ? [SEP]
02/19/2019 23:32:44 - INFO - utility_bert -   input_ids: 101 11523 14893 10372 45261 25659 107 151 24996 10686 10592 10855 10104 10103 12873 10114 10346 33413 107 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:32:44 - INFO - utility_bert -   *** Example ***
02/19/2019 23:32:44 - INFO - utility_bert -   guid: 38c016f3766fa6b06311
02/19/2019 23:32:44 - INFO - utility_bert -   tokens: [CLS] how do i practice sociology answer writing for ups ##c ex ##am ? [SEP]
02/19/2019 23:32:44 - INFO - utility_bert -   input_ids: 101 12548 10154 151 16710 57208 42942 16155 10139 61729 10261 11460 11064 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:32:44 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:33:02 - INFO - utility_bert -   *** Example ***
02/19/2019 23:33:02 - INFO - utility_bert -   guid: 0000455dfa3e01eae3af
02/19/2019 23:33:02 - INFO - utility_bert -   tokens: [CLS] can i convert mont ##ra hel ##ico ##n d to a mountain bike by just changing the tyre ##s ? [SEP]
02/19/2019 23:33:02 - INFO - utility_bert -   input_ids: 101 10743 151 81044 16403 10281 52364 12519 10115 146 10114 143 12309 59915 10151 12125 32330 10103 27862 10107 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:33:02 - INFO - utility_bert -   *** Example ***
02/19/2019 23:33:02 - INFO - utility_bert -   guid: 00004f9a462a357c33be
02/19/2019 23:33:02 - INFO - utility_bert -   tokens: [CLS] is gaza slowly becoming auschwitz , dachau or tre ##bli ##nka for palestinian ##s ? [SEP]
02/19/2019 23:33:02 - INFO - utility_bert -   input_ids: 101 10127 40090 54818 19641 43595 117 78855 10362 11555 37407 21290 10139 51492 10107 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:33:02 - INFO - utility_bert -   *** Example ***
02/19/2019 23:33:02 - INFO - utility_bert -   guid: 0000559f875832745e2e
02/19/2019 23:33:02 - INFO - utility_bert -   tokens: [CLS] is it crazy if i wash or wi ##pe my gr ##oce ##ries off ? ger ##ms are every ##w ##here . [SEP]
02/19/2019 23:33:02 - INFO - utility_bert -   input_ids: 101 10127 10197 26453 11526 151 58080 10362 19078 11599 11153 22153 46914 16362 11856 136 15079 12932 10320 13667 10650 30380 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:33:02 - INFO - utility_bert -   *** Example ***
02/19/2019 23:33:02 - INFO - utility_bert -   guid: 000075f67dd595c3deb5
02/19/2019 23:33:02 - INFO - utility_bert -   tokens: [CLS] what can you say about fem ##inis ##m ? [SEP]
02/19/2019 23:33:02 - INFO - utility_bert -   input_ids: 101 11523 10743 10855 16497 10935 19827 27533 10150 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   label: 0 (id = 0)
02/19/2019 23:33:02 - INFO - utility_bert -   *** Example ***
02/19/2019 23:33:02 - INFO - utility_bert -   guid: 000076f3b42776c692de
02/19/2019 23:33:02 - INFO - utility_bert -   tokens: [CLS] how were the calgary flames founded ? [SEP]
02/19/2019 23:33:02 - INFO - utility_bert -   input_ids: 101 12548 10342 10103 36881 50380 14153 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/19/2019 23:33:02 - INFO - utility_bert -   label: 0 (id = 0)
Done preprocessing:314.6s
02/19/2019 23:33:54 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz from cache at /home/tks/.pytorch_pretrained_bert/437da855f7aeb6dcc47ee03b11ac55bfbc069d31354f6867f3b298aad8429925.dd2dce7e7331017693bd2230dbc8015b12a975201a420a856a6efbf7ae9d84c5
02/19/2019 23:33:54 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/tks/.pytorch_pretrained_bert/437da855f7aeb6dcc47ee03b11ac55bfbc069d31354f6867f3b298aad8429925.dd2dce7e7331017693bd2230dbc8015b12a975201a420a856a6efbf7ae9d84c5 to temp dir /tmp/tmpw7t2to4s
02/19/2019 23:33:58 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 105879
}

#Params: 110654209
Epoch:1
step:2000 loss:0.1570598 time:701.8s
step:4000 loss:0.1324899 time:1403.9s
step:6000 loss:0.1228593 time:2106.0s
  F1:0.68521 threshold:0.38 AUC:0.96751 time:2904.0s
Epoch:2
step:2000 loss:0.0889359 time:702.5s
step:4000 loss:0.0887824 time:1405.0s
step:6000 loss:0.0880628 time:2107.3s
  F1:0.69112 threshold:0.36 AUC:0.96974 time:2904.6s
Epoch:3
step:2000 loss:0.0748593 time:701.9s
step:4000 loss:0.0742422 time:1403.9s
step:6000 loss:0.0738687 time:2106.0s
  F1:0.68976 threshold:0.36 AUC:0.96816 time:2903.6s
02/20/2019 01:59:16 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz from cache at /home/tks/.pytorch_pretrained_bert/437da855f7aeb6dcc47ee03b11ac55bfbc069d31354f6867f3b298aad8429925.dd2dce7e7331017693bd2230dbc8015b12a975201a420a856a6efbf7ae9d84c5
02/20/2019 01:59:16 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/tks/.pytorch_pretrained_bert/437da855f7aeb6dcc47ee03b11ac55bfbc069d31354f6867f3b298aad8429925.dd2dce7e7331017693bd2230dbc8015b12a975201a420a856a6efbf7ae9d84c5 to temp dir /tmp/tmpwg0zlxtm
02/20/2019 01:59:20 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 105879
}

Epoch:1
step:2000 loss:0.1514600 time:701.3s
step:4000 loss:0.1303095 time:1402.5s
step:6000 loss:0.1213895 time:2103.7s
  F1:0.68165 threshold:0.40 AUC:0.96733 time:2900.7s
Epoch:2
step:2000 loss:0.0890373 time:702.0s
step:4000 loss:0.0893482 time:1404.0s
step:6000 loss:0.0889735 time:2106.0s
  F1:0.69478 threshold:0.38 AUC:0.96922 time:2903.6s
Epoch:3
step:2000 loss:0.0751030 time:701.9s
step:4000 loss:0.0749963 time:1403.9s
step:6000 loss:0.0745060 time:2105.9s
  F1:0.69300 threshold:0.36 AUC:0.96825 time:2903.4s
02/20/2019 04:24:32 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz from cache at /home/tks/.pytorch_pretrained_bert/437da855f7aeb6dcc47ee03b11ac55bfbc069d31354f6867f3b298aad8429925.dd2dce7e7331017693bd2230dbc8015b12a975201a420a856a6efbf7ae9d84c5
02/20/2019 04:24:32 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/tks/.pytorch_pretrained_bert/437da855f7aeb6dcc47ee03b11ac55bfbc069d31354f6867f3b298aad8429925.dd2dce7e7331017693bd2230dbc8015b12a975201a420a856a6efbf7ae9d84c5 to temp dir /tmp/tmpso0mm4yz
02/20/2019 04:24:36 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 105879
}

Epoch:1
step:2000 loss:0.1454911 time:701.3s
step:4000 loss:0.1273163 time:1402.5s
step:6000 loss:0.1191523 time:2103.8s
  F1:0.68351 threshold:0.41 AUC:0.96767 time:2900.9s
Epoch:2
step:2000 loss:0.0885792 time:701.1s
step:4000 loss:0.0882389 time:1402.4s
step:6000 loss:0.0876483 time:2103.6s
  F1:0.69279 threshold:0.35 AUC:0.96948 time:2900.7s
Epoch:3
step:2000 loss:0.0735355 time:701.2s
step:4000 loss:0.0734561 time:1402.5s
step:6000 loss:0.0731639 time:2103.8s
  F1:0.69107 threshold:0.38 AUC:0.96850 time:2900.9s

Single
            F1      AUC  threshold
epoch                             
1      0.68346  0.96750    0.39583
2      0.69290  0.96948    0.36250
3      0.69128  0.96830    0.36667

Avg ensemble of 3models
            F1      AUC
epoch                  
1      0.68973  0.96912
2      0.69977  0.97083
3      0.69859  0.97002 


2902.5s/epoch
Done: 7.4 hours

Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Namespace(bert_model='bert-base-uncased', do_eval=False, do_lower_case=0, do_train=True, eval_batch_size=128, exp_name='base_uncased_12', exp_num=19, fold=0, fp16=False, gradient_accumulation_steps=8, learning_rate=5e-05, local_rank=-1, log_dir='log/', loss_scale=128, max_seq_length=50, n_bertlayers=12, n_dev=100000, n_folds=5, n_models=3, no_cuda=False, no_weight_decay=0, num_train_epochs=2.0, optimize_on_cpu=False, output_dir='./', pos_weight=None, seed=42, seed_split=4567, stratify=1, task_name='Quora', train_batch_size=64, warmup_proportion=0.1, weight_0=1.0, weight_1=1.0)
Train shape :  (1306122, 3)

Effective batch_size: 512
02/21/2019 02:07:16 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/tks/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
02/21/2019 02:08:30 - INFO - utility_bert -   *** Example ***
02/21/2019 02:08:30 - INFO - utility_bert -   guid: 1f07d75fede800e7d1df
02/21/2019 02:08:30 - INFO - utility_bert -   tokens: [CLS] what is lion tam ##ing ? [SEP]
02/21/2019 02:08:30 - INFO - utility_bert -   input_ids: 101 2054 2003 7006 17214 2075 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:08:30 - INFO - utility_bert -   *** Example ***
02/21/2019 02:08:30 - INFO - utility_bert -   guid: 0e5e0b66a17fb2b80c20
02/21/2019 02:08:30 - INFO - utility_bert -   tokens: [CLS] what are the most common data needs for non profits ? [SEP]
02/21/2019 02:08:30 - INFO - utility_bert -   input_ids: 101 2054 2024 1996 2087 2691 2951 3791 2005 2512 11372 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:08:30 - INFO - utility_bert -   *** Example ***
02/21/2019 02:08:30 - INFO - utility_bert -   guid: e9b7b430888864987165
02/21/2019 02:08:30 - INFO - utility_bert -   tokens: [CLS] what are some vacation packages that you recommend ? [SEP]
02/21/2019 02:08:30 - INFO - utility_bert -   input_ids: 101 2054 2024 2070 10885 14555 2008 2017 16755 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:08:30 - INFO - utility_bert -   *** Example ***
02/21/2019 02:08:30 - INFO - utility_bert -   guid: c236112ed981cd28356a
02/21/2019 02:08:30 - INFO - utility_bert -   tokens: [CLS] what is the nassau county sales tax rate ? [SEP]
02/21/2019 02:08:30 - INFO - utility_bert -   input_ids: 101 2054 2003 1996 14646 2221 4341 4171 3446 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:08:30 - INFO - utility_bert -   *** Example ***
02/21/2019 02:08:30 - INFO - utility_bert -   guid: d642137782d449475858
02/21/2019 02:08:30 - INFO - utility_bert -   tokens: [CLS] how does a sphere of influence relate to an american expansion ? [SEP]
02/21/2019 02:08:30 - INFO - utility_bert -   input_ids: 101 2129 2515 1037 10336 1997 3747 14396 2000 2019 2137 4935 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:08:30 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:20 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:20 - INFO - utility_bert -   guid: 14c71d5d5d052f551929
02/21/2019 02:11:20 - INFO - utility_bert -   tokens: [CLS] what is the reason for gibraltar â€™ s huge population ? [SEP]
02/21/2019 02:11:20 - INFO - utility_bert -   input_ids: 101 2054 2003 1996 3114 2005 12272 1521 1055 4121 2313 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:20 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:20 - INFO - utility_bert -   guid: 31a7f774b92c3f8b06de
02/21/2019 02:11:20 - INFO - utility_bert -   tokens: [CLS] do you think rejection or breakup leads to focus ##sing on career ? [SEP]
02/21/2019 02:11:20 - INFO - utility_bert -   input_ids: 101 2079 2017 2228 13893 2030 19010 5260 2000 3579 7741 2006 2476 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:20 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:20 - INFO - utility_bert -   guid: 824843436610ab46ed4e
02/21/2019 02:11:20 - INFO - utility_bert -   tokens: [CLS] how does the gender gap apply to retirement ? [SEP]
02/21/2019 02:11:20 - INFO - utility_bert -   input_ids: 101 2129 2515 1996 5907 6578 6611 2000 5075 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:20 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:20 - INFO - utility_bert -   guid: 66329bb6e3d64d9824e6
02/21/2019 02:11:20 - INFO - utility_bert -   tokens: [CLS] what does this sentence mean " i ind ##ul ##ge you in the right to be wrong " ? [SEP]
02/21/2019 02:11:20 - INFO - utility_bert -   input_ids: 101 2054 2515 2023 6251 2812 1000 1045 27427 5313 3351 2017 1999 1996 2157 2000 2022 3308 1000 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:20 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:20 - INFO - utility_bert -   guid: 38c016f3766fa6b06311
02/21/2019 02:11:20 - INFO - utility_bert -   tokens: [CLS] how do i practice sociology answer writing for ups ##c exam ? [SEP]
02/21/2019 02:11:20 - INFO - utility_bert -   input_ids: 101 2129 2079 1045 3218 11507 3437 3015 2005 11139 2278 11360 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:20 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:38 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:38 - INFO - utility_bert -   guid: 0000455dfa3e01eae3af
02/21/2019 02:11:38 - INFO - utility_bert -   tokens: [CLS] can i convert mont ##ra he ##lic ##on d to a mountain bike by just changing the tyres ? [SEP]
02/21/2019 02:11:38 - INFO - utility_bert -   input_ids: 101 2064 1045 10463 18318 2527 2002 10415 2239 1040 2000 1037 3137 7997 2011 2074 5278 1996 24656 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:38 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:38 - INFO - utility_bert -   guid: 00004f9a462a357c33be
02/21/2019 02:11:38 - INFO - utility_bert -   tokens: [CLS] is gaza slowly becoming auschwitz , da ##cha ##u or tre ##bl ##ink ##a for palestinians ? [SEP]
02/21/2019 02:11:38 - INFO - utility_bert -   input_ids: 101 2003 14474 3254 3352 24363 1010 4830 7507 2226 2030 29461 16558 19839 2050 2005 21524 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:38 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:38 - INFO - utility_bert -   guid: 0000559f875832745e2e
02/21/2019 02:11:38 - INFO - utility_bert -   tokens: [CLS] is it crazy if i wash or wipe my groceries off ? ge ##rm ##s are everywhere . [SEP]
02/21/2019 02:11:38 - INFO - utility_bert -   input_ids: 101 2003 2009 4689 2065 1045 9378 2030 13387 2026 26298 2125 1029 16216 10867 2015 2024 7249 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:38 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:38 - INFO - utility_bert -   guid: 000075f67dd595c3deb5
02/21/2019 02:11:38 - INFO - utility_bert -   tokens: [CLS] what can you say about feminism ? [SEP]
02/21/2019 02:11:38 - INFO - utility_bert -   input_ids: 101 2054 2064 2017 2360 2055 20050 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   label: 0 (id = 0)
02/21/2019 02:11:38 - INFO - utility_bert -   *** Example ***
02/21/2019 02:11:38 - INFO - utility_bert -   guid: 000076f3b42776c692de
02/21/2019 02:11:38 - INFO - utility_bert -   tokens: [CLS] how were the calgary flames founded ? [SEP]
02/21/2019 02:11:38 - INFO - utility_bert -   input_ids: 101 2129 2020 1996 10112 7311 2631 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/21/2019 02:11:38 - INFO - utility_bert -   label: 0 (id = 0)
Done preprocessing:317.6s
02/21/2019 02:12:31 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/tks/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02/21/2019 02:12:31 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/tks/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp0m_tqmhv
02/21/2019 02:12:33 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

#Params: 109483009
Epoch:1
step:2000 loss:0.1516821 time:979.6s
step:4000 loss:0.1281431 time:1959.8s
step:6000 loss:0.1176087 time:2939.9s
step:8000 loss:0.1119919 time:3919.9s
step:10000 loss:0.1076807 time:4899.8s
step:12000 loss:0.1050969 time:5879.7s
step:14000 loss:0.1028379 time:6859.6s
  F1:0.72005 threshold:0.36 AUC:0.97495 time:8130.1s
Epoch:2
step:2000 loss:0.0703235 time:979.9s
step:4000 loss:0.0705597 time:1959.9s
step:6000 loss:0.0703390 time:2939.9s
step:8000 loss:0.0695353 time:3919.9s
step:10000 loss:0.0690269 time:4899.8s
step:12000 loss:0.0690251 time:5879.7s
step:14000 loss:0.0688084 time:6859.9s
  F1:0.72207 threshold:0.35 AUC:0.97534 time:8130.3s
02/21/2019 06:43:39 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/tks/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02/21/2019 06:43:39 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/tks/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmplbvy4ag0
02/21/2019 06:43:41 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Epoch:1
step:2000 loss:0.1640833 time:980.0s
step:4000 loss:0.1338771 time:1960.0s
step:6000 loss:0.1219732 time:2940.0s
step:8000 loss:0.1151024 time:3919.9s
step:10000 loss:0.1106578 time:4899.9s
step:12000 loss:0.1074162 time:5879.9s
step:14000 loss:0.1050757 time:6860.0s
  F1:0.71878 threshold:0.46 AUC:0.97563 time:8130.1s
Epoch:2
step:2000 loss:0.0704584 time:979.9s
step:4000 loss:0.0701797 time:1959.9s
step:6000 loss:0.0697488 time:2939.9s
step:8000 loss:0.0692101 time:3919.8s
step:10000 loss:0.0688892 time:4899.8s
step:12000 loss:0.0686382 time:5880.1s
step:14000 loss:0.0685005 time:6860.0s
  F1:0.72190 threshold:0.35 AUC:0.97558 time:8130.2s
02/21/2019 11:14:44 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/tks/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02/21/2019 11:14:44 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/tks/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp9zvsx0s4
02/21/2019 11:14:47 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

Epoch:1
step:2000 loss:0.1922473 time:979.8s
step:4000 loss:0.1492200 time:1959.6s
step:6000 loss:0.1318095 time:2939.7s
step:8000 loss:0.1223922 time:3921.0s
step:10000 loss:0.1165367 time:4902.8s
step:12000 loss:0.1123939 time:5884.6s
step:14000 loss:0.1090445 time:6866.5s
  F1:0.71850 threshold:0.45 AUC:0.97513 time:8139.9s
Epoch:2
step:2000 loss:0.0696548 time:981.8s
step:4000 loss:0.0702121 time:1963.4s
step:6000 loss:0.0704325 time:2945.0s
step:8000 loss:0.0700647 time:3926.6s
step:10000 loss:0.0698953 time:4908.3s
step:12000 loss:0.0695994 time:5890.4s
step:14000 loss:0.0695023 time:6872.6s
  F1:0.72122 threshold:0.34 AUC:0.97520 time:8145.8s

Single
            F1      AUC  threshold
epoch                             
1      0.71911  0.97524    0.42500
2      0.72173  0.97537    0.34583

Avg ensemble of 3 models
            F1      AUC
epoch                  
1      0.72492  0.97650
2      0.72632  0.97673 


8134.4s/epoch
Done: 13.7 hours
